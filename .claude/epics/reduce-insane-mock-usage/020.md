---
epic: reduce-insane-mock-usage
task: 020
title: Create automated mock count tracking in CI
size: Small
parallel: true
depends_on: [019]
status: pending
created: 2025-09-20T02:15:00Z
updated: 2025-09-20T02:15:00Z
---

# Task 020: Create automated mock count tracking in CI

## Objective

Implement automated mock count tracking in the CI/CD pipeline to prevent mock
regression, enforce mock reduction goals, and provide continuous feedback on
mock usage trends.

## Background

To maintain the benefits of mock reduction and prevent teams from gradually
returning to over-mocking patterns, we need automated enforcement in the CI
pipeline. This system will track mock counts, enforce thresholds, and provide
immediate feedback on pull requests.

## Requirements

### 1. CI Pipeline Integration

Integrate mock tracking into CI/CD:

- **Pre-commit hooks** for early detection
- **Pull request checks** with detailed analysis
- **Build pipeline validation** with threshold enforcement
- **Deployment gates** for production releases
- **Scheduled monitoring** for trend analysis

### 2. Threshold Enforcement

Implement configurable thresholds:

- **Maximum mocks per file** (default: 3)
- **Total mock count limits** (target: <180 total)
- **Mock density per test tier** (unit/integration/e2e limits)
- **Quality score minimums** (target: >80)
- **Anti-pattern detection** with blocking rules

### 3. Feedback Mechanisms

Provide actionable feedback:

- **Immediate PR comments** with specific recommendations
- **Build failure details** with mock count breakdown
- **Trend notifications** for gradual increases
- **Success celebrations** for mock reductions
- **Team dashboards** for progress tracking

## Implementation Details

### 1. CI Mock Counter Script

```typescript
// scripts/ci-mock-counter.ts

export class CIMockCounter {
  private config: CIMockConfig
  private thresholds: MockThresholds

  constructor(config: CIMockConfig) {
    this.config = config
    this.thresholds = this.loadThresholds()
  }

  async runMockCheck(): Promise<CIMockResult> {
    console.log('üîç Running mock count analysis...')

    try {
      const currentMetrics = await this.collectCurrentMetrics()
      const baselineComparison = await this.compareWithBaseline(currentMetrics)
      const violations = this.checkThresholds(currentMetrics)
      const pullRequestAnalysis = await this.analyzePullRequestChanges()

      const result: CIMockResult = {
        success: violations.length === 0 && !pullRequestAnalysis?.shouldBlock,
        currentMetrics,
        baselineComparison,
        violations,
        pullRequestAnalysis,
        recommendations: this.generateRecommendations(
          violations,
          pullRequestAnalysis,
        ),
        timestamp: new Date().toISOString(),
      }

      await this.publishResults(result)
      await this.updateTrendData(currentMetrics)

      return result
    } catch (error) {
      console.error('‚ùå Mock count analysis failed:', error)
      throw error
    }
  }

  private async collectCurrentMetrics(): Promise<MockMetrics> {
    const testDirectories = [
      '__tests__/unit',
      '__tests__/integration',
      '__tests__/e2e',
      'packages/*/src/**/*.test.ts',
      'packages/*/src/**/*.spec.ts',
    ]

    let totalMocks = 0
    const mocksByFile: Record<string, number> = {}
    const mocksByType: Record<MockType, number> = {}
    const mocksByTier: Record<TestTier, number> = {}
    const violatingFiles: ViolatingFile[] = []

    for (const pattern of testDirectories) {
      const files = await glob(pattern)

      for (const file of files) {
        const content = await fs.readFile(file, 'utf-8')
        const fileMocks = this.countMocksInFile(content, file)

        totalMocks += fileMocks.count
        mocksByFile[file] = fileMocks.count

        // Track violations
        if (fileMocks.count > this.thresholds.maxMocksPerFile) {
          violatingFiles.push({
            path: file,
            mockCount: fileMocks.count,
            threshold: this.thresholds.maxMocksPerFile,
            severity:
              fileMocks.count > this.thresholds.maxMocksPerFile * 2
                ? 'critical'
                : 'high',
          })
        }

        // Count by type
        fileMocks.byType.forEach((count, type) => {
          mocksByType[type] = (mocksByType[type] || 0) + count
        })

        // Count by tier
        const tier = this.determineTierFromPath(file)
        mocksByTier[tier] = (mocksByTier[tier] || 0) + fileMocks.count
      }
    }

    const qualityScore = this.calculateQualityScore(
      totalMocks,
      mocksByType,
      violatingFiles,
    )

    return {
      timestamp: new Date().toISOString(),
      totalMocks,
      mocksByFile,
      mocksByType,
      mocksByTier,
      mockComplexity: this.calculateComplexityMetrics(mocksByFile),
      antiPatterns: this.detectAntiPatterns(mocksByFile, mocksByType),
      qualityScore,
      violatingFiles,
      trendAnalysis: await this.calculateTrendAnalysis(totalMocks),
    }
  }

  private countMocksInFile(content: string, filePath: string): FileMockCount {
    const lines = content.split('\n')
    let count = 0
    const byType = new Map<MockType, number>()
    const mockLocations: MockLocation[] = []

    lines.forEach((line, index) => {
      const mocks = this.detectMocksInLine(line, index + 1, filePath)
      count += mocks.length

      mocks.forEach((mock) => {
        byType.set(mock.type, (byType.get(mock.type) || 0) + 1)
        mockLocations.push(mock)
      })
    })

    return { count, byType, locations: mockLocations }
  }

  private detectMocksInLine(
    line: string,
    lineNumber: number,
    filePath: string,
  ): MockLocation[] {
    const mocks: MockLocation[] = []

    const mockPatterns = [
      { pattern: /vi\.mock\s*\(/g, type: MockType.MODULE },
      { pattern: /vi\.fn\s*\(/g, type: MockType.FUNCTION },
      { pattern: /vi\.spyOn\s*\(/g, type: MockType.SPY },
      { pattern: /jest\.mock\s*\(/g, type: MockType.MODULE },
      { pattern: /jest\.fn\s*\(/g, type: MockType.FUNCTION },
      { pattern: /jest\.spyOn\s*\(/g, type: MockType.SPY },
      { pattern: /mockImplementation\s*\(/g, type: MockType.IMPLEMENTATION },
      { pattern: /mockReturnValue\s*\(/g, type: MockType.RETURN_VALUE },
    ]

    mockPatterns.forEach(({ pattern, type }) => {
      let match
      while ((match = pattern.exec(line)) !== null) {
        mocks.push({
          type,
          line: lineNumber,
          column: match.index,
          context: line.trim(),
          filePath,
          severity: this.determineMockSeverity(type, line),
        })
      }
    })

    return mocks
  }

  private checkThresholds(metrics: MockMetrics): Violation[] {
    const violations: Violation[] = []

    // Total mock count check
    if (metrics.totalMocks > this.thresholds.maxTotalMocks) {
      violations.push({
        type: 'total-mocks-exceeded',
        severity: 'high',
        current: metrics.totalMocks,
        threshold: this.thresholds.maxTotalMocks,
        message: `Total mocks (${metrics.totalMocks}) exceed threshold (${this.thresholds.maxTotalMocks})`,
        recommendation:
          'Review high-mock files and consider converting to integration tests',
      })
    }

    // Quality score check
    if (metrics.qualityScore < this.thresholds.minQualityScore) {
      violations.push({
        type: 'quality-score-low',
        severity: 'medium',
        current: metrics.qualityScore,
        threshold: this.thresholds.minQualityScore,
        message: `Quality score (${metrics.qualityScore}) below threshold (${this.thresholds.minQualityScore})`,
        recommendation: 'Address anti-patterns and reduce mock complexity',
      })
    }

    // Per-file violations
    metrics.violatingFiles.forEach((file) => {
      violations.push({
        type: 'file-mock-limit-exceeded',
        severity: file.severity,
        current: file.mockCount,
        threshold: file.threshold,
        message: `File ${file.path} has ${file.mockCount} mocks (limit: ${file.threshold})`,
        recommendation:
          'Consider splitting test or converting to integration test',
        filePath: file.path,
      })
    })

    // Anti-pattern violations
    const criticalAntiPatterns = metrics.antiPatterns.filter(
      (p) => p.severity === 'critical',
    )
    if (criticalAntiPatterns.length > 0) {
      violations.push({
        type: 'critical-anti-patterns',
        severity: 'critical',
        current: criticalAntiPatterns.length,
        threshold: 0,
        message: `${criticalAntiPatterns.length} critical anti-pattern(s) detected`,
        recommendation: 'Address critical anti-patterns before proceeding',
        details: criticalAntiPatterns.map((p) => p.description),
      })
    }

    return violations
  }

  private async publishResults(result: CIMockResult): Promise<void> {
    // Print results to console
    this.printConsoleResults(result)

    // Create CI artifacts
    await this.createCIArtifacts(result)

    // Post to pull request if applicable
    if (this.isInPullRequest()) {
      await this.postToPullRequest(result)
    }

    // Send notifications for failures
    if (!result.success && this.config.notificationsEnabled) {
      await this.sendNotifications(result)
    }

    // Update GitHub status check
    if (this.config.githubStatusCheck) {
      await this.updateGitHubStatus(result)
    }
  }

  private printConsoleResults(result: CIMockResult): void {
    if (result.success) {
      console.log('‚úÖ Mock count check passed!')
      console.log(`üìä Current metrics:`)
      console.log(`   Total mocks: ${result.currentMetrics.totalMocks}`)
      console.log(`   Quality score: ${result.currentMetrics.qualityScore}/100`)
      console.log(
        `   Files checked: ${Object.keys(result.currentMetrics.mocksByFile).length}`,
      )

      if (result.baselineComparison) {
        const change =
          result.currentMetrics.totalMocks - result.baselineComparison.baseline
        const changeIndicator = change > 0 ? 'üìà' : change < 0 ? 'üìâ' : '‚û°Ô∏è'
        console.log(
          `   Change from baseline: ${changeIndicator} ${change > 0 ? '+' : ''}${change}`,
        )
      }
    } else {
      console.log('‚ùå Mock count check failed!')
      console.log(`üìä Current metrics:`)
      console.log(`   Total mocks: ${result.currentMetrics.totalMocks}`)
      console.log(`   Quality score: ${result.currentMetrics.qualityScore}/100`)

      console.log('\nüö® Violations:')
      result.violations.forEach((violation, index) => {
        const icon = { low: '‚ö†Ô∏è', medium: 'üî∂', high: 'üî¥', critical: 'üö®' }[
          violation.severity
        ]
        console.log(`   ${index + 1}. ${icon} ${violation.message}`)
        console.log(`      üí° ${violation.recommendation}`)
      })

      console.log('\nüí° Recommendations:')
      result.recommendations.forEach((rec, index) => {
        console.log(`   ${index + 1}. ${rec}`)
      })
    }
  }

  private async createCIArtifacts(result: CIMockResult): Promise<void> {
    const artifactsDir = process.env.CI_ARTIFACTS_DIR || './ci-artifacts'
    await fs.ensureDir(artifactsDir)

    // Save detailed results
    await fs.writeFile(
      path.join(artifactsDir, 'mock-analysis-results.json'),
      JSON.stringify(result, null, 2),
    )

    // Generate HTML report
    const htmlReport = this.generateHtmlReport(result)
    await fs.writeFile(
      path.join(artifactsDir, 'mock-analysis-report.html'),
      htmlReport,
    )

    // Generate CSV summary for trend analysis
    const csvSummary = this.generateCsvSummary(result)
    await fs.writeFile(
      path.join(artifactsDir, 'mock-metrics-summary.csv'),
      csvSummary,
    )
  }

  private async postToPullRequest(result: CIMockResult): Promise<void> {
    if (!process.env.GITHUB_TOKEN) {
      console.log('‚ö†Ô∏è GITHUB_TOKEN not available, skipping PR comment')
      return
    }

    const comment = this.generatePullRequestComment(result)

    try {
      // Use GitHub CLI or API to post comment
      await this.executeCommand(
        `gh pr comment --body "${comment.replace(/"/g, '\\"')}"`,
      )
      console.log('üìù Posted mock analysis to PR')
    } catch (error) {
      console.error('‚ùå Failed to post PR comment:', error)
    }
  }

  private generatePullRequestComment(result: CIMockResult): string {
    const statusIcon = result.success ? '‚úÖ' : '‚ùå'
    const status = result.success ? 'PASSED' : 'FAILED'

    let comment = `## Mock Usage Analysis ${statusIcon} ${status}

### üìä Current Metrics
- **Total Mocks**: ${result.currentMetrics.totalMocks}
- **Quality Score**: ${result.currentMetrics.qualityScore}/100
- **Files Analyzed**: ${Object.keys(result.currentMetrics.mocksByFile).length}
`

    if (result.baselineComparison) {
      const change =
        result.currentMetrics.totalMocks - result.baselineComparison.baseline
      const trend =
        change > 0
          ? 'üìà Increased'
          : change < 0
            ? 'üìâ Decreased'
            : '‚û°Ô∏è No change'
      comment += `- **Change from Baseline**: ${trend} (${change > 0 ? '+' : ''}${change})\n`
    }

    if (result.pullRequestAnalysis) {
      comment += `\n### üîÑ Pull Request Changes
- **Mocks Added**: ${result.pullRequestAnalysis.mocksAdded}
- **Mocks Removed**: ${result.pullRequestAnalysis.mocksRemoved}
- **Net Change**: ${result.pullRequestAnalysis.netChange > 0 ? '+' : ''}${result.pullRequestAnalysis.netChange}
`
    }

    if (result.violations.length > 0) {
      comment += `\n### üö® Violations
${result.violations.map((v) => `- **${v.type}**: ${v.message}`).join('\n')}
`
    }

    if (result.recommendations.length > 0) {
      comment += `\n### üí° Recommendations
${result.recommendations.map((r) => `- ${r}`).join('\n')}
`
    }

    comment += `\n---
*Mock analysis performed at ${new Date(result.timestamp).toLocaleString()}*
*For more details, see the [testing guidelines](link-to-guidelines)*`

    return comment
  }

  private generateHtmlReport(result: CIMockResult): string {
    return `
<!DOCTYPE html>
<html>
<head>
    <title>Mock Usage CI Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background: ${result.success ? '#d4edda' : '#f8d7da'}; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
        .metric { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; }
        .violation { background: #f8d7da; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 5px solid #dc3545; }
        .success { color: #155724; }
        .error { color: #721c24; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <div class="header">
        <h1 class="${result.success ? 'success' : 'error'}">
            Mock Usage CI Report - ${result.success ? 'PASSED' : 'FAILED'}
        </h1>
        <p>Generated: ${new Date(result.timestamp).toLocaleString()}</p>
    </div>

    <div class="metric">
        <h2>Summary</h2>
        <ul>
            <li>Total Mocks: ${result.currentMetrics.totalMocks}</li>
            <li>Quality Score: ${result.currentMetrics.qualityScore}/100</li>
            <li>Files Analyzed: ${Object.keys(result.currentMetrics.mocksByFile).length}</li>
            <li>Violations: ${result.violations.length}</li>
        </ul>
    </div>

    ${
      result.violations.length > 0
        ? `
    <h2>Violations</h2>
    ${result.violations
      .map(
        (v) => `
        <div class="violation">
            <h3>${v.type} (${v.severity})</h3>
            <p>${v.message}</p>
            <p><strong>Recommendation:</strong> ${v.recommendation}</p>
        </div>
    `,
      )
      .join('')}
    `
        : ''
    }

    <h2>Mock Distribution</h2>
    <table>
        <tr><th>File</th><th>Mock Count</th><th>Status</th></tr>
        ${Object.entries(result.currentMetrics.mocksByFile)
          .sort(([, a], [, b]) => b - a)
          .slice(0, 20)
          .map(
            ([file, count]) => `
            <tr>
                <td>${file}</td>
                <td>${count}</td>
                <td>${count > this.thresholds.maxMocksPerFile ? '‚ö†Ô∏è Over limit' : '‚úÖ OK'}</td>
            </tr>
        `,
          )
          .join('')}
    </table>
</body>
</html>
    `
  }

  private loadThresholds(): MockThresholds {
    const defaultThresholds: MockThresholds = {
      maxTotalMocks: 180,
      maxMocksPerFile: 3,
      minQualityScore: 80,
      maxInternalMocks: 20,
      maxUtilityMocks: 10,
      maxConsoleMocks: 5,
      maxUnitMockRatio: 0.6,
    }

    try {
      const configPath = path.join(process.cwd(), '.mock-thresholds.json')
      if (fs.existsSync(configPath)) {
        const customThresholds = JSON.parse(
          fs.readFileSync(configPath, 'utf-8'),
        )
        return { ...defaultThresholds, ...customThresholds }
      }
    } catch (error) {
      console.warn('‚ö†Ô∏è Failed to load custom thresholds, using defaults')
    }

    return defaultThresholds
  }
}

interface CIMockConfig {
  testDirectories: string[]
  excludePatterns: string[]
  thresholdsFile?: string
  notificationsEnabled: boolean
  githubStatusCheck: boolean
  artifactsEnabled: boolean
}

interface CIMockResult {
  success: boolean
  currentMetrics: MockMetrics
  baselineComparison?: BaselineComparison
  violations: Violation[]
  pullRequestAnalysis?: PullRequestAnalysis
  recommendations: string[]
  timestamp: string
}

interface FileMockCount {
  count: number
  byType: Map<MockType, number>
  locations: MockLocation[]
}

interface MockLocation {
  type: MockType
  line: number
  column: number
  context: string
  filePath: string
  severity: 'low' | 'medium' | 'high'
}

interface ViolatingFile {
  path: string
  mockCount: number
  threshold: number
  severity: 'high' | 'critical'
}
```

### 2. GitHub Actions Workflow

```yaml
# .github/workflows/mock-count-check.yml
name: Mock Count Check

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]
  schedule:
    # Run daily at 9 AM UTC
    - cron: '0 9 * * *'

jobs:
  mock-analysis:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch full history for comparison

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run mock count analysis
        id: mock-check
        run: |
          npm run mock:check
          echo "mock-check-result=$?" >> $GITHUB_OUTPUT
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          CI: true
          CI_ARTIFACTS_DIR: ./artifacts

      - name: Upload analysis artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mock-analysis-results
          path: ./artifacts/
          retention-days: 30

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = './artifacts/mock-analysis-results.json';

            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));

              const comment = `## Mock Usage Analysis ${results.success ? '‚úÖ' : '‚ùå'}

**Total Mocks**: ${results.currentMetrics.totalMocks}
**Quality Score**: ${results.currentMetrics.qualityScore}/100

${results.violations.length > 0 ? `**Violations**:
${results.violations.map(v => `- ${v.message}`).join('\n')}` : 'No violations detected! üéâ'}

View detailed report in the artifacts.`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

      - name: Update commit status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = './artifacts/mock-analysis-results.json';

            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));

              github.rest.repos.createCommitStatus({
                owner: context.repo.owner,
                repo: context.repo.repo,
                sha: context.sha,
                state: results.success ? 'success' : 'failure',
                target_url: `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
                description: results.success
                  ? `${results.currentMetrics.totalMocks} mocks, quality score: ${results.currentMetrics.qualityScore}/100`
                  : `${results.violations.length} violations detected`,
                context: 'mock-usage-check'
              });
            }

      - name: Fail if violations found
        if: steps.mock-check.outputs.mock-check-result != '0'
        run: |
          echo "‚ùå Mock usage check failed. See artifacts for details."
          exit 1
```

### 3. Package.json Scripts

```json
{
  "scripts": {
    "mock:check": "node scripts/ci-mock-counter.js",
    "mock:check:local": "node scripts/ci-mock-counter.js --local",
    "mock:baseline": "node scripts/ci-mock-counter.js --set-baseline",
    "mock:report": "node scripts/ci-mock-counter.js --report-only",
    "mock:dashboard": "node scripts/generate-mock-dashboard.js",
    "precommit:mock-check": "node scripts/ci-mock-counter.js --precommit"
  }
}
```

### 4. Pre-commit Hook Integration

```bash
#!/bin/sh
# .husky/pre-commit

echo "üîç Running pre-commit mock check..."

# Run mock check in pre-commit mode (faster, less verbose)
npm run precommit:mock-check

if [ $? -ne 0 ]; then
  echo "‚ùå Pre-commit mock check failed!"
  echo "üí° Run 'npm run mock:check:local' for detailed analysis"
  echo "üìö See testing guidelines: [link-to-guidelines]"
  exit 1
fi

echo "‚úÖ Mock check passed!"
```

### 5. Configuration and Thresholds

```json
// .mock-thresholds.json
{
  "maxTotalMocks": 180,
  "maxMocksPerFile": 3,
  "minQualityScore": 80,
  "maxInternalMocks": 20,
  "maxUtilityMocks": 10,
  "maxConsoleMocks": 5,
  "maxUnitMockRatio": 0.6,
  "warningThresholds": {
    "totalMocks": 150,
    "qualityScore": 85,
    "mocksPerFile": 2
  },
  "excludePatterns": [
    "**/node_modules/**",
    "**/dist/**",
    "**/*.d.ts",
    "**/legacy-tests/**"
  ],
  "notifications": {
    "enabled": true,
    "webhookUrl": "${MOCK_CHECK_WEBHOOK_URL}",
    "channels": ["#engineering", "#testing"]
  }
}
```

### 6. Notification System

```typescript
// scripts/mock-check-notifier.ts

export class MockCheckNotifier {
  async sendNotification(
    result: CIMockResult,
    config: NotificationConfig,
  ): Promise<void> {
    if (!result.success && config.onFailure) {
      await this.sendFailureNotification(result, config)
    }

    if (
      result.success &&
      this.isSignificantImprovement(result) &&
      config.onImprovement
    ) {
      await this.sendImprovementNotification(result, config)
    }

    if (this.isDailyReport() && config.dailyReport) {
      await this.sendDailyReport(result, config)
    }
  }

  private async sendFailureNotification(
    result: CIMockResult,
    config: NotificationConfig,
  ): Promise<void> {
    const message = {
      text: `üö® Mock Usage Check Failed`,
      blocks: [
        {
          type: 'header',
          text: {
            type: 'plain_text',
            text: 'Mock Usage Check Failed',
          },
        },
        {
          type: 'section',
          fields: [
            {
              type: 'mrkdwn',
              text: `*Total Mocks:* ${result.currentMetrics.totalMocks}`,
            },
            {
              type: 'mrkdwn',
              text: `*Quality Score:* ${result.currentMetrics.qualityScore}/100`,
            },
            {
              type: 'mrkdwn',
              text: `*Violations:* ${result.violations.length}`,
            },
            {
              type: 'mrkdwn',
              text: `*Branch:* ${process.env.GITHUB_REF_NAME || 'unknown'}`,
            },
          ],
        },
        {
          type: 'section',
          text: {
            type: 'mrkdwn',
            text: `*Top Violations:*\n${result.violations
              .slice(0, 3)
              .map((v) => `‚Ä¢ ${v.message}`)
              .join('\n')}`,
          },
        },
        {
          type: 'actions',
          elements: [
            {
              type: 'button',
              text: {
                type: 'plain_text',
                text: 'View Details',
              },
              url: `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`,
            },
          ],
        },
      ],
    }

    await this.sendToSlack(message, config.slackWebhook)
  }

  private async sendImprovementNotification(
    result: CIMockResult,
    config: NotificationConfig,
  ): Promise<void> {
    const improvement = this.calculateImprovement(result)

    const message = {
      text: `üéâ Mock Usage Improvement Detected!`,
      blocks: [
        {
          type: 'header',
          text: {
            type: 'plain_text',
            text: 'üéâ Mock Usage Improvement!',
          },
        },
        {
          type: 'section',
          text: {
            type: 'mrkdwn',
            text: `Great job! The team has made significant progress in reducing mock usage.`,
          },
        },
        {
          type: 'section',
          fields: [
            {
              type: 'mrkdwn',
              text: `*Mocks Reduced:* ${improvement.mocksReduced}`,
            },
            {
              type: 'mrkdwn',
              text: `*Quality Score:* ${result.currentMetrics.qualityScore}/100 (+${improvement.qualityIncrease})`,
            },
          ],
        },
      ],
    }

    await this.sendToSlack(message, config.slackWebhook)
  }
}

interface NotificationConfig {
  onFailure: boolean
  onImprovement: boolean
  dailyReport: boolean
  slackWebhook?: string
  emailRecipients?: string[]
  webhookUrl?: string
}
```

## Acceptance Criteria

- [ ] CI script implemented and integrated into build pipeline
- [ ] GitHub Actions workflow created with proper permissions
- [ ] Threshold configuration system with customizable limits
- [ ] Pull request comment system providing actionable feedback
- [ ] Pre-commit hooks preventing mock introduction
- [ ] Artifact generation for detailed analysis
- [ ] GitHub status checks integration
- [ ] Notification system for failures and improvements
- [ ] Baseline comparison system for trend analysis
- [ ] Dashboard generation for team visibility
- [ ] Configuration file system for team customization
- [ ] Documentation and setup guide for teams

## Benefits

1. **Automated Prevention**: Stops mock regression before it reaches main branch
2. **Immediate Feedback**: Developers get instant feedback on mock usage
3. **Trend Tracking**: Historical data shows long-term progress
4. **Team Awareness**: Regular notifications keep team focused on goals
5. **Quality Gates**: Prevents deployment of over-mocked code

## Notes

- Start with warning-only mode before enforcing hard limits
- Configure thresholds based on team's current baseline
- Ensure CI script is fast enough not to slow down development
- Provide clear documentation for developers on fixing violations
- Consider exemptions for special cases (e.g., legacy code, external library
  testing)
